{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Stock Predictor Using Closing Prices\n",
    "\n",
    "In this notebook, you will build and train a custom LSTM RNN that uses a 10 day window of Bitcoin closing prices to predict the 11th day closing price. \n",
    "\n",
    "You will need to:\n",
    "\n",
    "1. Prepare the data for training and testing\n",
    "2. Build and train a custom LSTM RNN\n",
    "3. Evaluate the performance of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "In this section, you will need to prepare the training and testing data for the model. The model will use a rolling 10 day window to predict the 11th day closing price.\n",
    "\n",
    "You will need to:\n",
    "1. Use the `window_data` function to generate the X and y values for the model.\n",
    "2. Split the data into 70% training and 30% testing\n",
    "3. Apply the MinMaxScaler to the X and y values\n",
    "4. Reshape the X_train and X_test data for the model. Note: The required input format for the LSTM is:\n",
    "\n",
    "```python\n",
    "reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hvplot.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "# Note: This is for the homework solution, but it is good practice to comment this out and run multiple experiments to evaluate your model\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import random\n",
    "random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fng_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-07-29</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-28</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-27</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-26</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-25</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fng_value\n",
       "date                  \n",
       "2019-07-29          19\n",
       "2019-07-28          16\n",
       "2019-07-27          47\n",
       "2019-07-26          24\n",
       "2019-07-25          42"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the fear and greed sentiment data for Bitcoin\n",
    "df = pd.read_csv('btc_sentiment.csv', index_col=\"date\", infer_datetime_format=True, parse_dates=True)\n",
    "df = df.drop(columns=\"fng_classification\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2019-07-25    9882.429688\n",
       "2019-07-26    9847.450195\n",
       "2019-07-27    9478.320313\n",
       "2019-07-28    9531.769531\n",
       "2019-07-29    9529.889648\n",
       "Name: Close, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the historical closing prices for bitcoin\n",
    "df2 = pd.read_csv('btc_historic.csv', index_col=\"Date\", infer_datetime_format=True, parse_dates=True)['Close']\n",
    "df2 = df2.sort_index()\n",
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fng_value</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-07-25</th>\n",
       "      <td>42</td>\n",
       "      <td>9882.429688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-26</th>\n",
       "      <td>24</td>\n",
       "      <td>9847.450195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-27</th>\n",
       "      <td>47</td>\n",
       "      <td>9478.320313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-28</th>\n",
       "      <td>16</td>\n",
       "      <td>9531.769531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-29</th>\n",
       "      <td>19</td>\n",
       "      <td>9529.889648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fng_value        Close\n",
       "2019-07-25          42  9882.429688\n",
       "2019-07-26          24  9847.450195\n",
       "2019-07-27          47  9478.320313\n",
       "2019-07-28          16  9531.769531\n",
       "2019-07-29          19  9529.889648"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join the data into a single DataFrame\n",
    "df = df.join(df2, how=\"inner\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fng_value</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-02-01</th>\n",
       "      <td>30</td>\n",
       "      <td>9114.719727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-02</th>\n",
       "      <td>15</td>\n",
       "      <td>8870.820313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-03</th>\n",
       "      <td>40</td>\n",
       "      <td>9251.269531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-04</th>\n",
       "      <td>24</td>\n",
       "      <td>8218.049805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-05</th>\n",
       "      <td>11</td>\n",
       "      <td>6937.080078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fng_value        Close\n",
       "2018-02-01          30  9114.719727\n",
       "2018-02-02          15  8870.820313\n",
       "2018-02-03          40  9251.269531\n",
       "2018-02-04          24  8218.049805\n",
       "2018-02-05          11  6937.080078"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function accepts the column number for the features (X) and the target (y)\n",
    "# It chunks the data up with a rolling window of Xt-n to predict Xt\n",
    "# It returns a numpy array of X any y\n",
    "def window_data(df, window, feature_col_number, target_col_number):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window - 1):\n",
    "        features = df.iloc[i:(i + window), feature_col_number]\n",
    "        target = df.iloc[(i + window), target_col_number]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Closing Prices using a 10 day window of previous closing prices\n",
    "# Try a window size anywhere from 1 to 10 and see how the model performance changes\n",
    "window_size = 1\n",
    "\n",
    "# Column index 1 is the `Close` column\n",
    "feature_column = 1\n",
    "target_column = 1\n",
    "X, y = window_data(df, window_size, feature_column, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(X)\n",
    "#display(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 70% of the data for training and the remaineder for testing\n",
    "def window_data(df, window, feature_col_number, target_col_number): \n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window - 1):\n",
    "        features = df.iloc[i : (i + window), feature_col_number]\n",
    "        target = df.iloc[(i + window), target_col_number]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X sample values:\n",
      "[[ 9114.719727  8870.820313  9251.269531  8218.049805  6937.080078\n",
      "   7701.25      7592.720215  8260.69043   8696.830078  8569.290039\n",
      "   8084.609863  8911.269531  8544.69043   9485.639648 10033.75\n",
      "  10188.730469 11097.209961 10417.230469 11182.280273 11256.429688\n",
      "  10481.660156  9847.959961 10175.509766  9705.730469  9610.110352\n",
      "  10326.5      10594.759766 10334.44043  10929.370117 11043.120117]\n",
      " [ 8870.820313  9251.269531  8218.049805  6937.080078  7701.25\n",
      "   7592.720215  8260.69043   8696.830078  8569.290039  8084.609863\n",
      "   8911.269531  8544.69043   9485.639648 10033.75     10188.730469\n",
      "  11097.209961 10417.230469 11182.280273 11256.429688 10481.660156\n",
      "   9847.959961 10175.509766  9705.730469  9610.110352 10326.5\n",
      "  10594.759766 10334.44043  10929.370117 11043.120117 11465.360352]\n",
      " [ 9251.269531  8218.049805  6937.080078  7701.25      7592.720215\n",
      "   8260.69043   8696.830078  8569.290039  8084.609863  8911.269531\n",
      "   8544.69043   9485.639648 10033.75     10188.730469 11097.209961\n",
      "  10417.230469 11182.280273 11256.429688 10481.660156  9847.959961\n",
      "  10175.509766  9705.730469  9610.110352 10326.5      10594.759766\n",
      "  10334.44043  10929.370117 11043.120117 11465.360352 11504.419922]] \n",
      "\n",
      "y sample values:\n",
      "[[11465.360352]\n",
      " [11504.419922]\n",
      " [11440.730469]]\n"
     ]
    }
   ],
   "source": [
    "# Define the window size\n",
    "window_size = 30\n",
    "\n",
    "# Set the index of the feature and target columns\n",
    "feature_column = 1\n",
    "target_column = 1\n",
    "\n",
    "# Create the features (X) and target (y) data using the window_data() function.\n",
    "X, y = window_data(df, window_size, feature_column, target_column)\n",
    "\n",
    "# Print a few sample values from X and y\n",
    "print (f\"X sample values:\\n{X[:3]} \\n\")\n",
    "print (f\"y sample values:\\n{y[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually splitting the data\n",
    "split = int(0.7 * len(X))\n",
    "\n",
    "X_train = X[: split - 1]\n",
    "X_test = X[split:]\n",
    "\n",
    "y_train = y[: split - 1]\n",
    "y_test = y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use MinMaxScaler to scale the data between 0 and 1. \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create a MinMaxScaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the MinMaxScaler object with the features data X\n",
    "scaler.fit(X)\n",
    "\n",
    "# Scale the features training and testing sets\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Fit the MinMaxScaler object with the target data Y\n",
    "scaler.fit(y)\n",
    "\n",
    "# Scale the target training and testing sets\n",
    "y_train = scaler.transform(y_train)\n",
    "y_test = scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train sample values:\n",
      "[[[0.60761794]\n",
      "  [0.58242373]\n",
      "  [0.62172321]\n",
      "  [0.51499412]\n",
      "  [0.38267307]\n",
      "  [0.46160996]\n",
      "  [0.4503991 ]\n",
      "  [0.5193988 ]\n",
      "  [0.56445096]\n",
      "  [0.55127638]\n",
      "  [0.5012101 ]\n",
      "  [0.58660203]\n",
      "  [0.5487353 ]\n",
      "  [0.64593307]\n",
      "  [0.70255153]\n",
      "  [0.71856064]\n",
      "  [0.81240436]\n",
      "  [0.74216413]\n",
      "  [0.82119191]\n",
      "  [0.82885137]\n",
      "  [0.74881956]\n",
      "  [0.68335987]\n",
      "  [0.71719497]\n",
      "  [0.66866791]\n",
      "  [0.65879059]\n",
      "  [0.7327919 ]\n",
      "  [0.76050248]\n",
      "  [0.73361212]\n",
      "  [0.79506691]\n",
      "  [0.80681701]]\n",
      "\n",
      " [[0.58242373]\n",
      "  [0.62172321]\n",
      "  [0.51499412]\n",
      "  [0.38267307]\n",
      "  [0.46160996]\n",
      "  [0.4503991 ]\n",
      "  [0.5193988 ]\n",
      "  [0.56445096]\n",
      "  [0.55127638]\n",
      "  [0.5012101 ]\n",
      "  [0.58660203]\n",
      "  [0.5487353 ]\n",
      "  [0.64593307]\n",
      "  [0.70255153]\n",
      "  [0.71856064]\n",
      "  [0.81240436]\n",
      "  [0.74216413]\n",
      "  [0.82119191]\n",
      "  [0.82885137]\n",
      "  [0.74881956]\n",
      "  [0.68335987]\n",
      "  [0.71719497]\n",
      "  [0.66866791]\n",
      "  [0.65879059]\n",
      "  [0.7327919 ]\n",
      "  [0.76050248]\n",
      "  [0.73361212]\n",
      "  [0.79506691]\n",
      "  [0.80681701]\n",
      "  [0.8504334 ]]\n",
      "\n",
      " [[0.62172321]\n",
      "  [0.51499412]\n",
      "  [0.38267307]\n",
      "  [0.46160996]\n",
      "  [0.4503991 ]\n",
      "  [0.5193988 ]\n",
      "  [0.56445096]\n",
      "  [0.55127638]\n",
      "  [0.5012101 ]\n",
      "  [0.58660203]\n",
      "  [0.5487353 ]\n",
      "  [0.64593307]\n",
      "  [0.70255153]\n",
      "  [0.71856064]\n",
      "  [0.81240436]\n",
      "  [0.74216413]\n",
      "  [0.82119191]\n",
      "  [0.82885137]\n",
      "  [0.74881956]\n",
      "  [0.68335987]\n",
      "  [0.71719497]\n",
      "  [0.66866791]\n",
      "  [0.65879059]\n",
      "  [0.7327919 ]\n",
      "  [0.76050248]\n",
      "  [0.73361212]\n",
      "  [0.79506691]\n",
      "  [0.80681701]\n",
      "  [0.8504334 ]\n",
      "  [0.85446816]]] \n",
      "\n",
      "X_test sample values:\n",
      "[[[0.02281946]\n",
      "  [0.01918649]\n",
      "  [0.02424393]\n",
      "  [0.02424393]\n",
      "  [0.02082684]\n",
      "  [0.02366753]\n",
      "  [0.02852768]\n",
      "  [0.02242695]\n",
      "  [0.02052832]\n",
      "  [0.02222446]\n",
      "  [0.01677345]\n",
      "  [0.01475297]\n",
      "  [0.04416178]\n",
      "  [0.04335915]\n",
      "  [0.04675556]\n",
      "  [0.03913222]\n",
      "  [0.03975922]\n",
      "  [0.03856719]\n",
      "  [0.03679562]\n",
      "  [0.03728835]\n",
      "  [0.03974167]\n",
      "  [0.04528668]\n",
      "  [0.04528668]\n",
      "  [0.07024855]\n",
      "  [0.07145402]\n",
      "  [0.07659928]\n",
      "  [0.07277624]\n",
      "  [0.07757854]\n",
      "  [0.09468047]\n",
      "  [0.05568876]]\n",
      "\n",
      " [[0.01918649]\n",
      "  [0.02424393]\n",
      "  [0.02424393]\n",
      "  [0.02082684]\n",
      "  [0.02366753]\n",
      "  [0.02852768]\n",
      "  [0.02242695]\n",
      "  [0.02052832]\n",
      "  [0.02222446]\n",
      "  [0.01677345]\n",
      "  [0.01475297]\n",
      "  [0.04416178]\n",
      "  [0.04335915]\n",
      "  [0.04675556]\n",
      "  [0.03913222]\n",
      "  [0.03975922]\n",
      "  [0.03856719]\n",
      "  [0.03679562]\n",
      "  [0.03728835]\n",
      "  [0.03974167]\n",
      "  [0.04528668]\n",
      "  [0.04528668]\n",
      "  [0.07024855]\n",
      "  [0.07145402]\n",
      "  [0.07659928]\n",
      "  [0.07277624]\n",
      "  [0.07757854]\n",
      "  [0.09468047]\n",
      "  [0.05568876]\n",
      "  [0.06332141]]\n",
      "\n",
      " [[0.02424393]\n",
      "  [0.02424393]\n",
      "  [0.02082684]\n",
      "  [0.02366753]\n",
      "  [0.02852768]\n",
      "  [0.02242695]\n",
      "  [0.02052832]\n",
      "  [0.02222446]\n",
      "  [0.01677345]\n",
      "  [0.01475297]\n",
      "  [0.04416178]\n",
      "  [0.04335915]\n",
      "  [0.04675556]\n",
      "  [0.03913222]\n",
      "  [0.03975922]\n",
      "  [0.03856719]\n",
      "  [0.03679562]\n",
      "  [0.03728835]\n",
      "  [0.03974167]\n",
      "  [0.04528668]\n",
      "  [0.04528668]\n",
      "  [0.07024855]\n",
      "  [0.07145402]\n",
      "  [0.07659928]\n",
      "  [0.07277624]\n",
      "  [0.07757854]\n",
      "  [0.09468047]\n",
      "  [0.05568876]\n",
      "  [0.06332141]\n",
      "  [0.06046728]]]\n"
     ]
    }
   ],
   "source": [
    "# Reshape the features for the model\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Print some sample data after reshaping the datasets\n",
    "print (f\"X_train sample values:\\n{X_train[:3]} \\n\")\n",
    "print (f\"X_test sample values:\\n{X_test[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Train the LSTM RNN\n",
    "\n",
    "In this section, you will design a custom LSTM RNN and fit (train) it using the training data.\n",
    "\n",
    "You will need to:\n",
    "1. Define the model architecture\n",
    "2. Compile the model\n",
    "3. Fit the model to the training data\n",
    "\n",
    "### Hints:\n",
    "You will want to use the same model architecture and random seed for both notebooks. This is necessary to accurately compare the performance of the FNG model vs the closing price model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM model. \n",
    "# The return sequences need to be set to True if you are adding additional LSTM layers, but \n",
    "# You don't have to do this for the final layer. \n",
    "# YOUR CODE HERE!\n",
    "\n",
    "# Model set-up\n",
    "model = Sequential()\n",
    "\n",
    "# Initial model setup\n",
    "number_units = 30\n",
    "dropout_fraction = 0.2\n",
    "\n",
    "# Layer 1\n",
    "model.add(LSTM(\n",
    "    units=number_units,\n",
    "    return_sequences=True,\n",
    "    input_shape=(X_train.shape[1], 1))\n",
    "    )\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Layer 2\n",
    "model.add(LSTM(units=number_units, return_sequences=True))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Layer 3\n",
    "model.add(LSTM(units=number_units))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 30, 30)            3840      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 30, 30)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 30, 30)            7320      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 30)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 30)                7320      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 18,511\n",
      "Trainable params: 18,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 357 samples\n",
      "Epoch 1/10\n",
      "357/357 [==============================] - 6s 17ms/sample - loss: 0.1149\n",
      "Epoch 2/10\n",
      "357/357 [==============================] - 0s 676us/sample - loss: 0.0481\n",
      "Epoch 3/10\n",
      "357/357 [==============================] - 0s 695us/sample - loss: 0.0229\n",
      "Epoch 4/10\n",
      "357/357 [==============================] - 0s 695us/sample - loss: 0.0226\n",
      "Epoch 5/10\n",
      "357/357 [==============================] - 0s 675us/sample - loss: 0.0109\n",
      "Epoch 6/10\n",
      "357/357 [==============================] - 0s 682us/sample - loss: 0.0147\n",
      "Epoch 7/10\n",
      "357/357 [==============================] - 0s 679us/sample - loss: 0.0153\n",
      "Epoch 8/10\n",
      "357/357 [==============================] - 0s 694us/sample - loss: 0.0115\n",
      "Epoch 9/10\n",
      "357/357 [==============================] - 0s 703us/sample - loss: 0.0111\n",
      "Epoch 10/10\n",
      "357/357 [==============================] - ETA: 0s - loss: 0.011 - 0s 701us/sample - loss: 0.0101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21134a45a08>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "# Use at least 10 epochs\n",
    "# Do not shuffle the data\n",
    "# Experiement with the batch size, but a smaller batch size is recommended\n",
    "# YOUR CODE HERE!\n",
    "model.fit(X_train, y_train, epochs=10, shuffle=False, batch_size=90, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance\n",
    "\n",
    "In this section, you will evaluate the model using the test data. \n",
    "\n",
    "You will need to:\n",
    "1. Evaluate the model using the `X_test` and `y_test` data.\n",
    "2. Use the X_test data to make predictions\n",
    "3. Create a DataFrame of Real (y_test) vs predicted values. \n",
    "4. Plot the Real vs predicted values as a line chart\n",
    "\n",
    "### Hints\n",
    "Remember to apply the `inverse_transform` function to the predicted and y_test values to recover the actual closing prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01738521425271189"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some predictions\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover the original prices instead of the scaled version\n",
    "predicted_prices = scaler.inverse_transform(predicted)\n",
    "real_prices = scaler.inverse_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3232.51001</td>\n",
       "      <td>4315.861816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3232.51001</td>\n",
       "      <td>4333.770508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3232.51001</td>\n",
       "      <td>4350.761719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3232.51001</td>\n",
       "      <td>4366.132324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3232.51001</td>\n",
       "      <td>4379.858887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Real    Predicted\n",
       "0  3232.51001  4315.861816\n",
       "1  3232.51001  4333.770508\n",
       "2  3232.51001  4350.761719\n",
       "3  3232.51001  4366.132324\n",
       "4  3232.51001  4379.858887"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame of Real and Predicted values\n",
    "stocks = pd.DataFrame({\n",
    "    \"Real\": real_prices.ravel(),\n",
    "    \"Predicted\": predicted_prices.ravel()\n",
    "})\n",
    "stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21143893288>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the real vs predicted values as a line chart\n",
    "stocks.plot(title=\"Real Vs. Predicted \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
